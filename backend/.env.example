# ==============================================
# Multi-LLM Provider Configuration
# ==============================================
# We use different LLMs for different tasks to optimize cost and performance:
# - Ollama (Local): FREE local GPU inference - ALWAYS TRIED FIRST ($0/unlimited)
# - GPT-4o-mini: Fast, cheap calculations ($0.15/1M tokens)
# - Claude Sonnet: Balanced reasoning ($3/1M tokens)
# - Claude Opus: Complex legal analysis ($15/1M tokens)
# - Gemini: Multimodal, experimental features (free tier)
# - Grok: Real-time data, cutting-edge (beta)

# üöÄ Ollama (Local LLM - FREE, no API key needed)
# Install: https://ollama.ai
# Recommended models:
#   - llama3.2:latest (general purpose, good quality)
#   - llama3.2:1b (faster, lower VRAM)
#   - mistral:latest (alternative, good for reasoning)
# Run: ollama pull llama3.2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest

# Anthropic API (Primary - Claude Sonnet/Opus)
ANTHROPIC_API_KEY=sk-ant-xxx

# OpenAI API (For GPT-4o-mini calculations)
OPENAI_API_KEY=sk-proj-xxx

# Google AI API (For Gemini multimodal tasks)
GOOGLE_API_KEY=AIzaSy-xxx

# xAI API (For Grok real-time features)
XAI_API_KEY=xai-xxx

# üåê Groq (Online Ollama Alternative - FREE, no local setup needed!)
# Get free API key: https://console.groq.com/
# Automatically used when local Ollama is not available
GROQ_API_KEY=gsk_xxx
GROQ_MODEL=llama-3.2-90b-text-preview

# Database
DATABASE_URL=postgresql://user:pass@ep-xxx.us-east-2.aws.neon.tech/aioscrew

# Neo4j (for contract knowledge graph)
NEO4J_URI=neo4j+s://xxx.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=xxx
NEO4J_DATABASE=neo4j

# Server
PORT=3001
NODE_ENV=development
FRONTEND_URL=http://localhost:5173
